# v6.0.0 Breaking Changes Plan

**Status:** PLANNED - Not yet implemented
**Target Release:** Q2 2026 (approximately 6 months after v5.11.0)
**Current Version:** v5.11.0
**Strategy:** Major version with breaking changes that improve module quality and consistency

---

## Overview

Version 6.0.0 will include breaking changes that have been deferred from v5.11.0 to maintain backward compatibility. All breaking changes have been communicated to users through deprecation warnings in v5.11.0.

**Key Principles:**
- Users have had 6+ months to migrate from deprecated features
- All breaking changes improve code quality, consistency, or security
- Migration path is well-documented in UPGRADE-6.0.md
- Breaking changes are grouped into a single release to minimize upgrade fatigue

---

## Breaking Changes

### 1. Remove Deprecated Variables with Typos

**Status:** Ready to implement
**Deprecation Notice:** Added in v5.11.0
**Migration Path:** UPGRADE-6.0.md provides detailed instructions

#### 1.1 Remove `alb_healthcheck_uhealthy_threshold`

**Current State (v5.11.0):**
```hcl
variable "alb_healthcheck_uhealthy_threshold" {
  description = "⚠️ DEPRECATED - Use 'alb_healthcheck_unhealthy_threshold' instead"
  type        = number
  default     = null
}

variable "alb_healthcheck_unhealthy_threshold" {
  description = "Number of consecutive health check failures required before considering the target unhealthy"
  type        = number
  default     = 2
}

locals {
  unhealthy_threshold = coalesce(
    var.alb_healthcheck_unhealthy_threshold,
    var.alb_healthcheck_uhealthy_threshold,
  )
}
```

**After v6.0.0:**
```hcl
# Remove deprecated variable entirely
variable "alb_healthcheck_unhealthy_threshold" {
  description = "Number of consecutive health check failures required before considering the target unhealthy"
  type        = number
  default     = 2
}

# No need for coalesce logic - use variable directly
# In main.tf:
unhealthy_threshold = var.alb_healthcheck_unhealthy_threshold
```

**Rationale:**
- **Code Quality:** Removes confusing typo'd variable name
- **Maintainability:** Simplifies codebase by removing compatibility layer
- **User Experience:** Forces users to use correct, self-documenting variable name
- **Technical Debt:** Eliminates code added solely for backward compatibility

**Implementation Steps:**
1. Remove `variable "alb_healthcheck_uhealthy_threshold"` from variables.tf
2. Remove coalesce logic from locals.tf for `unhealthy_threshold`
3. Update main.tf to use `var.alb_healthcheck_unhealthy_threshold` directly
4. Remove deprecation check from deprecations.tf
5. Update tests to use correct variable name
6. Update README.md (terraform-docs will regenerate)

**Files to Update:**
- `variables.tf` (line 42-50: remove deprecated variable)
- `locals.tf` (line 58-61: remove coalesce logic, use variable directly)
- `main.tf` (line 124: use var directly instead of local)
- `deprecations.tf` (remove check block for this variable)
- `tests/*.py` (if any tests explicitly use the deprecated variable)

---

#### 1.2 Remove `attach_tagret_group_to_asg`

**Current State (v5.11.0):**
```hcl
variable "attach_tagret_group_to_asg" {
  description = "⚠️ DEPRECATED - Use 'attach_target_group_to_asg' instead"
  type        = bool
  default     = null
}

variable "attach_target_group_to_asg" {
  description = "Whether to register ASG instances in the target group. Disable if using ECS which registers targets itself."
  type        = bool
  default     = true
}

locals {
  attach_tg_to_asg = coalesce(
    var.attach_target_group_to_asg,
    var.attach_tagret_group_to_asg,
  )
}
```

**After v6.0.0:**
```hcl
# Remove deprecated variable entirely
variable "attach_target_group_to_asg" {
  description = "Whether to register ASG instances in the target group. Disable if using ECS which registers targets itself."
  type        = bool
  default     = true
}

# No need for coalesce logic - use variable directly
# In asg.tf:
target_group_arns = var.target_group_type == "instance" && var.attach_target_group_to_asg ? [aws_alb_target_group.website.arn] : []
```

**Rationale:**
- Same as above: removes typo, simplifies code, improves maintainability

**Implementation Steps:**
1. Remove `variable "attach_tagret_group_to_asg"` from variables.tf
2. Remove coalesce logic from locals.tf for `attach_tg_to_asg`
3. Update asg.tf to use `var.attach_target_group_to_asg` directly
4. Remove deprecation check from deprecations.tf
5. Update tests to use correct variable name
6. Update README.md

**Files to Update:**
- `variables.tf` (line 419-427: remove deprecated variable)
- `locals.tf` (line 63-66: remove coalesce logic)
- `asg.tf` (line 13: use var directly instead of local)
- `deprecations.tf` (remove check block for this variable)
- `tests/*.py` (if any tests explicitly use the deprecated variable)

---

### 2. Change `alb_healthcheck_port` Type from `any` to `string`

**Status:** Planned, needs implementation design
**Current Issue:** Type `any` is an anti-pattern in Terraform

**Current State (v5.11.0):**
```hcl
variable "alb_healthcheck_port" {
  description = "Port of the webserver that the elb will check to determine whether the instance is healthy or not"
  type        = any
  default     = 80
}
```

**Proposed for v6.0.0:**
```hcl
variable "alb_healthcheck_port" {
  description = <<-EOF
    Port of the webserver that the ELB will check to determine whether the instance is healthy or not.
    Can be a port number (e.g., "8080") or the special value "traffic-port" to use the same port as target_group_port.
  EOF
  type        = string
  default     = "80"

  validation {
    condition     = can(tonumber(var.alb_healthcheck_port)) || var.alb_healthcheck_port == "traffic-port"
    error_message = "The alb_healthcheck_port must be a valid port number or 'traffic-port'."
  }
}
```

**Rationale:**
- **Type Safety:** `any` defeats Terraform's type checking system
- **Best Practices:** Type `any` is explicitly discouraged in Terraform best practices
- **Documentation:** Validation makes acceptable values clear
- **Error Prevention:** Catches invalid values at plan time instead of apply time
- **AWS API:** AWS accepts both numeric ports and the string "traffic-port"

**Migration Impact:**
- Users passing unquoted numbers (e.g., `alb_healthcheck_port = 8080`) must quote them
- Change is required but very simple: add quotes
- Can be caught with validation in v5.x to warn users

**Implementation Steps:**
1. Change type from `any` to `string` in variables.tf
2. Change default from `80` to `"80"`
3. Add validation rule
4. Update all examples in README.md to use quoted strings
5. Test with both numeric strings and "traffic-port"

**Files to Update:**
- `variables.tf` (line 24-28: change type and default)
- `README.md` (update examples)
- `tests/*.py` (ensure tests use quoted strings)

**Prerequisite for v5.x (Optional Warning):**
Could add a check in v5.11.x to warn users:
```hcl
check "alb_healthcheck_port_type_warning" {
  assert {
    condition     = can(regex("^\\d+$", tostring(var.alb_healthcheck_port))) || var.alb_healthcheck_port == "traffic-port"
    error_message = <<-EOF
      ⚠️  FUTURE BREAKING CHANGE ⚠️

      In v6.0.0, alb_healthcheck_port will require a string type.

      If you're using: alb_healthcheck_port = 8080
      Change to:       alb_healthcheck_port = "8080"

      This is a warning only - your current configuration works but will break in v6.0.0.
    EOF
  }
}
```

---

### 3. Migrate to infrahouse/s3-bucket Module for Access Logs

**Status:** Under Consideration
**Decision Required:** Whether to proceed with this breaking change
**Complexity:** High - requires data migration strategy

**Current State:**
```hcl
# Direct S3 resource management
resource "aws_s3_bucket" "access_log" {
  count         = var.alb_access_log_enabled ? 1 : 0
  bucket_prefix = "${var.alb_name_prefix}-access-log-"
  force_destroy = var.alb_access_log_force_destroy
}

resource "aws_s3_bucket_server_side_encryption_configuration" "access_log" {
  # ...
}

resource "aws_s3_bucket_versioning" "access_log" {
  # ...
}

resource "aws_s3_bucket_policy" "access_logs" {
  # ...
}

# etc.
```

**Proposed for v6.0.0:**
```hcl
# Use shared s3-bucket module
module "access_log_bucket" {
  source  = "infrahouse/s3-bucket/aws"
  version = "~> 1.0"  # Verify current version
  count   = var.alb_access_log_enabled ? 1 : 0

  bucket_prefix = "${var.alb_name_prefix}-access-log-"
  force_destroy = var.alb_access_log_force_destroy

  # Custom bucket policy for ELB service account access
  bucket_policy = data.aws_iam_policy_document.access_logs[0].json

  # ISO compliance settings automatically applied by module:
  # - Encryption (AES256 or KMS)
  # - Versioning
  # - Public access blocking
  # - Lifecycle policies
  # - Required tags
  # - Logging (if configured)
}

# Keep existing bucket policy data source
data "aws_iam_policy_document" "access_logs" {
  count = var.alb_access_log_enabled ? 1 : 0
  # ... existing policy for ELB access
}
```

**Rationale:**
- **Consistency:** All InfraHouse modules use the same S3 bucket configuration
- **Compliance:** Automatically applies ISO compliance standards
- **DRY Principle:** Don't repeat S3 best practices across modules
- **Maintenance:** S3 compliance updates happen in one place
- **Future-Proof:** New compliance requirements automatically inherited
- **Less Code:** Removes ~100 lines of S3-specific resource management

**Challenges:**
- **State Migration:** Terraform will want to destroy and recreate bucket
- **Data Loss Risk:** Existing access logs would be lost
- **Complex Migration:** Requires `moved` blocks or manual state manipulation
- **User Burden:** Users must follow exact migration steps

**Migration Strategies:**

#### Option A: Terraform `moved` Blocks (Recommended)
```hcl
# Add to s3.tf during v6.0.0 upgrade
moved {
  from = aws_s3_bucket.access_log
  to   = module.access_log_bucket.aws_s3_bucket.this
}

moved {
  from = aws_s3_bucket_policy.access_logs
  to   = module.access_log_bucket.aws_s3_bucket_policy.this
}

moved {
  from = aws_s3_bucket_server_side_encryption_configuration.access_log
  to   = module.access_log_bucket.aws_s3_bucket_server_side_encryption_configuration.this
}

moved {
  from = aws_s3_bucket_versioning.access_log
  to   = module.access_log_bucket.aws_s3_bucket_versioning.this
}

# ... additional moved blocks for all S3 resources
```

**Prerequisites:**
- Verify exact resource names in s3-bucket module source code
- s3-bucket module must support all current features:
  - `bucket_prefix`
  - `force_destroy`
  - Custom bucket policies
  - Count-based conditional creation

**Risks:**
- If s3-bucket module changes its internal structure, `moved` blocks break
- Users who don't follow exact upgrade steps risk data loss

#### Option B: Documented Manual Migration
Provide detailed UPGRADE-6.0.md instructions:
```bash
# 1. Backup current bucket name
BUCKET_NAME=$(terraform state show 'aws_s3_bucket.access_log[0]' | grep bucket | head -1 | awk '{print $3}')

# 2. Upgrade to v6.0.0
# ... terraform will plan to destroy old bucket and create new one

# 3. Import existing bucket to new module
terraform import 'module.access_log_bucket[0].aws_s3_bucket.this' $BUCKET_NAME

# 4. Import other resources
terraform import 'module.access_log_bucket[0].aws_s3_bucket_policy.this' $BUCKET_NAME
# ... etc

# 5. Run terraform plan - should show no changes
```

**Risks:**
- Very error-prone
- Easy to make a mistake and lose data
- Not atomic - partial failure leaves state inconsistent

#### Option C: Defer to v7.0.0
- v6.0.0 is already a major version with breaking changes
- Adding another risky breaking change might be too much
- Consider deferring S3 module migration to v7.0.0
- Allows more time to:
  - Ensure s3-bucket module is stable and feature-complete
  - Develop better migration tooling
  - Get user feedback on v6.0.0 other changes first

**Decision Point:**
- **If s3-bucket module migration is HIGH priority for compliance:** Include in v6.0.0 with Option A (moved blocks)
- **If compliance is already met with current approach:** Defer to v7.0.0

**Implementation Steps (if proceeding):**
1. Audit s3-bucket module to ensure all features are supported
2. Create test environment to verify `moved` blocks work correctly
3. Document exact internal resource paths from s3-bucket module
4. Add `moved` blocks to s3.tf
5. Replace direct S3 resources with module call
6. Test migration with real bucket (in test account)
7. Document migration process in UPGRADE-6.0.md
8. Consider adding safety checks in module that detect old state and provide helpful error

**Files to Update:**
- `s3.tf` (complete rewrite to use module)
- `UPGRADE-6.0.md` (detailed migration instructions)
- `tests/*.py` (update to work with module structure)

---

### 4. Enforce Stricter Variable Validations

**Status:** Planned
**Current State:** Some validations exist in v5.11.0 but are permissive
**Goal:** Add validations that might break existing invalid configurations

#### 4.1 Enforce Healthcheck Timeout < Interval

**Current (v5.11.0):**
```hcl
# Warning only via check block
check "healthcheck_timeout_less_than_interval" {
  assert {
    condition     = var.alb_healthcheck_timeout < var.alb_healthcheck_interval
    error_message = "Health check timeout must be less than interval..."
  }
}
```

**Proposed for v6.0.0:**
```hcl
# Hard validation that blocks plan
variable "alb_healthcheck_timeout" {
  description = "Number of seconds to timeout a check"
  type        = number
  default     = 4

  validation {
    condition     = var.alb_healthcheck_timeout >= 2 && var.alb_healthcheck_timeout <= 120
    error_message = "Health check timeout must be between 2 and 120 seconds."
  }
}

# Cross-validation using a validation resource
resource "terraform_data" "healthcheck_validation" {
  lifecycle {
    precondition {
      condition     = var.alb_healthcheck_timeout < var.alb_healthcheck_interval
      error_message = <<-EOF
        Health check timeout (${var.alb_healthcheck_timeout}s) must be less than
        health check interval (${var.alb_healthcheck_interval}s).

        This is required by AWS API. Please adjust your configuration.
      EOF
    }
  }
}
```

**Rationale:**
- AWS API rejects timeout >= interval
- Better to fail at plan time with clear message than at apply time with cryptic AWS error
- v5.11.0 only warns; v6.0.0 enforces

**Impact:**
- Any configuration with timeout >= interval will fail plan
- Forces users to fix invalid configuration before proceeding

---

### 5. Enable ALB Access Logging by Default

**Status:** Planned
**Security Rationale:** Access logging is a security best practice and compliance requirement
**Current:** `alb_access_log_enabled = false` (disabled by default)
**Proposed:** `alb_access_log_enabled = true` (enabled by default)

**Current State (v5.11.0):**
```hcl
variable "alb_access_log_enabled" {
  description = "Whether to maintain the access log."
  type        = bool
  default     = false  # Disabled - users must opt-in
}
```

**Proposed for v6.0.0:**
```hcl
variable "alb_access_log_enabled" {
  description = <<-EOF
    Whether to enable ALB access logging to S3.

    Access logs provide detailed records of all requests and are essential for:
    - Security investigations and incident response
    - Debugging production issues
    - Compliance requirements (SOC2, HIPAA, PCI-DSS)
    - AWS Well-Architected Framework best practices

    When enabled, creates an encrypted, versioned S3 bucket for access logs.
    Storage costs are minimal compared to the security and operational benefits.

    Disable only if you have alternative centralized logging (e.g., AWS CloudWatch Logs).
  EOF
  type        = bool
  default     = true  # Enabled by default for security and compliance
}
```

**Rationale:**
- **Security Best Practice:** Access logs are critical for security monitoring and incident response
  - Track unauthorized access attempts
  - Identify suspicious traffic patterns
  - Forensic analysis after security incidents
  - Meet AWS Well-Architected Framework security pillar recommendations

- **Compliance Requirements:** Many frameworks require access logging
  - SOC2: Logging and monitoring controls
  - HIPAA: Access audit controls
  - PCI-DSS: Logging and monitoring of network resources
  - ISO 27001: Information security event logging

- **Operational Benefits:**
  - Debug production issues (5xx errors, slow requests)
  - Analyze traffic patterns and usage
  - Capacity planning and optimization
  - Troubleshooting without needing to reproduce issues

- **Low Cost:**
  - S3 storage is inexpensive (~$0.023/GB/month in us-east-1)
  - Typical access log sizes are small
  - Can add lifecycle policies to archive/delete old logs
  - Security and compliance value far outweighs cost

- **Now Secure by Default (as of v5.11.0):**
  - Encryption enabled (AES256)
  - Versioning enabled (audit trail)
  - Public access blocked
  - All AWS regions supported
  - Proper IAM policies for ELB service account access

**Migration Impact:**

**Breaking Change:**
When users upgrade to v6.0.0, if they don't explicitly set `alb_access_log_enabled = false`:
1. A new S3 bucket will be created: `{alb_name_prefix}-access-log-{random}`
2. ALB will be updated to enable access logging
3. Access logs will start being written to S3
4. Minimal cost impact (storage costs begin accruing)

**Users who should opt-out:**
```hcl
module "website" {
  source  = "infrahouse/website-pod/aws"
  version = "~> 6.0"

  # Explicitly disable if:
  # - Using alternative centralized logging (CloudWatch Logs, Splunk, etc.)
  # - Internal/development environment where logging is not required
  # - Cost-sensitive non-production environment
  alb_access_log_enabled = false
}
```

**Implementation Steps:**
1. Update `variables.tf`: Change `default = false` to `default = true`
2. Update variable description to explain benefits (use HEREDOC format)
3. Update UPGRADE-6.0.md with migration instructions
4. Update CHANGELOG.md to highlight this breaking change
5. Add note to README.md about access logging being enabled by default
6. Update all example configurations to show the default
7. Update tests to handle new S3 buckets

**Files to Update:**
- `variables.tf` (line 1-5: change default and improve description)
- `UPGRADE-6.0.md` (add section explaining this breaking change)
- `CHANGELOG.md` (highlight in breaking changes section)
- `README.md` (update security features section)
- `examples/` (if any - show default behavior)

**Communication Strategy:**
In UPGRADE-6.0.md, be very clear:
```markdown
### Access Logging Enabled by Default

**v5.x behavior:** ALB access logging was disabled by default.
**v6.0.0 behavior:** ALB access logging is enabled by default.

**What this means:**
- A new S3 bucket will be created for access logs (encrypted, versioned)
- ALB will start writing access logs to this bucket
- You will incur minimal S3 storage costs

**If you don't want access logging:**
Set `alb_access_log_enabled = false` in your module configuration.

**Why this change:**
Access logging is a security best practice and required for many compliance frameworks.
By enabling it by default, we help users follow security best practices without additional configuration.
```

**Estimated Cost Impact:**
Example for a moderately-used ALB:
- Traffic: 1M requests/day
- Log size: ~500 bytes/request (typical)
- Daily logs: ~500 MB
- Monthly logs: ~15 GB
- S3 Standard cost: ~$0.35/month
- **Annual cost: ~$4** (for security and compliance benefits)

For high-traffic ALBs, costs scale but remain reasonable:
- 100M requests/day → ~1.5TB/month → ~$35/month
- Can add lifecycle policies to reduce costs:
  - Transition to S3-IA after 30 days
  - Transition to Glacier after 90 days
  - Delete after 1 year (or as required by compliance)

**Rollback Option:**
If a user upgrades to v6.0.0 and realizes they don't want access logging:
```hcl
# Add to configuration
alb_access_log_enabled = false

# Apply changes
terraform apply

# This will:
# 1. Disable access logging on ALB
# 2. Delete S3 bucket (if force_destroy = true)
# 3. Stop incurring storage costs
```

**Testing Requirements:**
- Verify S3 bucket is created with correct configuration
- Verify ALB starts writing logs to bucket
- Verify encryption and versioning are working
- Test opt-out scenario (setting to false)
- Test upgrade path from v5.x (bucket gets created)

---

### 6. Require CloudWatch Alarms for Vanta Compliance

**Status:** Planned
**Introduced in:** v5.12.0 (optional)
**Made Required in:** v6.0.0 (breaking)
**Compliance Rationale:** Vanta requires ALB monitoring for production environments

**Current State (v5.12.0):**
```hcl
variable "alarm_emails" {
  description = <<-EOF
    List of email addresses to receive CloudWatch alarm notifications for ALB monitoring.

    Vanta Compliance: Creates alarms for unhealthy hosts, latency, and 5xx errors.

    In v6.0.0, at least one email will be required.
  EOF
  type        = list(string)
  default     = []  # Optional
}

variable "alarm_topic_arns" {
  description = "List of existing SNS topic ARNs for alarm integrations"
  type        = list(string)
  default     = []
}

# Warning check block in v5.12.0
check "vanta_alarms_recommended" {
  assert {
    condition     = length(var.alarm_emails) > 0 || length(var.alarm_topic_arns) > 0
    error_message = "⚠️  VANTA COMPLIANCE RECOMMENDATION - Configure alarm_emails"
  }
}
```

**Proposed for v6.0.0:**
```hcl
variable "alarm_emails" {
  description = <<-EOF
    List of email addresses to receive CloudWatch alarm notifications for ALB monitoring.
    AWS will send confirmation emails that must be accepted.

    **Required for Vanta Compliance:**
    Creates CloudWatch alarms for:
    - Load balancer unhealthy host count monitoring
    - Load balancer latency monitoring
    - Load balancer server errors (5xx) monitoring

    At least one email address must be provided.
  EOF
  type        = list(string)

  validation {
    condition     = length(var.alarm_emails) > 0
    error_message = "At least one email address must be provided for alarm notifications (required for Vanta compliance)"
  }
}

variable "alarm_topic_arns" {
  description = <<-EOF
    List of existing SNS topic ARNs to send ALB alarms to.
    Use this for advanced integrations like PagerDuty, Slack, OpsGenie, etc.

    These topics will receive notifications in addition to configured alarm_emails.
  EOF
  type        = list(string)
  default     = []
}

# Remove warning check block - validation now enforces requirement
```

**Rationale:**

- **Vanta Compliance Requirement:** Vanta explicitly requires monitoring for:
  - Load balancer unhealthy host count
  - Load balancer latency
  - Load balancer server errors (5xx)

- **Production Readiness:** CloudWatch alarms are essential for:
  - Incident detection and response
  - Service level objective (SLO) monitoring
  - Proactive issue identification
  - On-call engineer notifications

- **Security Best Practice:**
  - Monitoring is a foundational security control
  - Early detection of attacks or degradation
  - Meets AWS Well-Architected Framework requirements
  - Required for SOC2, ISO 27001, and similar frameworks

- **Low Cost:**
  - CloudWatch alarms are free for first 10 alarms per month
  - 3 alarms created by this module (well within free tier)
  - SNS email notifications are free
  - Minimal cost compared to compliance and operational value

**Migration Impact:**

**Breaking Change:**
When users upgrade to v6.0.0 without `alarm_emails` configured:
```
Error: Invalid value for variable

At least one email address must be provided for alarm notifications
(required for Vanta compliance)
```

**Required Action:**
```hcl
module "website" {
  source  = "infrahouse/website-pod/aws"
  version = "~> 6.0"

  # REQUIRED in v6.0.0
  alarm_emails = ["ops-team@example.com"]

  # ... other configuration
}
```

**Users who should opt-out:**
There is no opt-out. If you're using this module for production workloads requiring Vanta compliance, alarms are mandatory.

For non-production environments where Vanta compliance is not required, consider:
1. Using development email addresses
2. Creating a dedicated SNS topic with no subscribers
3. Using a different module version (v5.x)

**Alternative Pattern (Advanced):**
If you have centralized monitoring via existing SNS topics:
```hcl
module "website" {
  source  = "infrahouse/website-pod/aws"
  version = "~> 6.0"

  # Satisfy requirement with placeholder
  alarm_emails = ["devnull@example.com"]

  # Your actual alerting via existing infrastructure
  alarm_topic_arns = [
    aws_sns_topic.centralized_monitoring.arn
  ]
}
```

**Implementation Steps:**
1. Update `variables.tf`: Add validation to `alarm_emails` requiring length > 0
2. Remove `default = []` from `alarm_emails` variable
3. Remove warning check block from `deprecations.tf`
4. Update UPGRADE-6.0.md with migration instructions
5. Update CHANGELOG.md highlighting this breaking change
6. Update tests to always provide `alarm_emails`

**Files to Update:**
- `variables.tf` (add validation, remove default)
- `deprecations.tf` (remove check block)
- `UPGRADE-6.0.md` (add migration section)
- `CHANGELOG.md` (highlight breaking change)
- `tests/*.py` (add alarm_emails to all test fixtures)

**Communication Strategy:**

In UPGRADE-6.0.md:
```markdown
### CloudWatch Alarms Required for Vanta Compliance

**v5.x behavior:** CloudWatch alarms were optional (configured via alarm_emails).
**v6.0.0 behavior:** At least one alarm_emails address is required.

**What this means:**
- You must provide at least one email address for alarm notifications
- CloudWatch alarms will be created for unhealthy hosts, latency, and 5xx errors
- Email recipients will receive SNS confirmation emails (must click to confirm)

**Migration:**
```hcl
module "website" {
  source  = "infrahouse/website-pod/aws"
  version = "~> 6.0"

  # Add this (required)
  alarm_emails = ["ops-team@example.com", "on-call@example.com"]

  # Optional: customize thresholds
  alarm_unhealthy_host_threshold       = 1
  alarm_target_response_time_threshold = 2.0
  alarm_5xx_threshold                  = 10
}
```

**Why this change:**
Vanta compliance explicitly requires ALB monitoring. By making alarms mandatory,
we ensure all production deployments meet compliance requirements by default.

**Cost Impact:**
- CloudWatch: First 10 alarms free, then $0.10/alarm/month ($0.30/month for 3 alarms)
- SNS: Email notifications are free
- Total cost: ~$0.30/month (or free if within first 10 alarms across account)
```

**Testing Requirements:**
- Verify validation error when `alarm_emails` is empty or not provided
- Verify validation error when `alarm_emails = []`
- Verify success when `alarm_emails = ["test@example.com"]`
- Update all existing tests to include alarm_emails
- Test upgrade path from v5.12.0 → v6.0.0

**Estimated Impact:**
- **High adoption risk:** All users must update configuration
- **Low technical risk:** Simple validation, well-tested in v5.12.0
- **High value:** Ensures Vanta compliance for all users

---

## Additional Improvements to Consider

### 7. Remove `alb_idle_timeout` Default of 60s

**Status:** Under Consideration
**Current:** Default is 60 seconds
**AWS Default:** 60 seconds
**Issue:** Explicitly setting a default that matches AWS default is redundant

**Rationale:**
- If AWS changes their default, module doesn't automatically inherit it
- Module should only set defaults that differ from AWS

**Recommendation:** Change default from `60` to `null` or remove variable entirely if it's rarely used

---

### 6. Consolidate Vanta Tags into Map

**Status:** Low Priority
**Current:** Individual vanta_* variables (7 different variables)
**Proposed:** Single `vanta_tags` map

**Rationale:**
- Reduces variable count
- More flexible - can add new Vanta tags without module changes
- Matches pattern used for general `tags` variable

**Impact:**
- Breaking change to variable interface
- May not be worth the disruption

---

## Implementation Timeline

### Phase 1: Preparation (During v5.11.x releases)
- Monitor deprecation warnings in user deployments
- Gather feedback on migration pain points
- Finalize decision on S3 module migration
- Write comprehensive UPGRADE-6.0.md
- Create automated migration test suite

### Phase 2: Alpha Release (v6.0.0-alpha.1)
- Implement breaking changes
- Test with internal InfraHouse projects
- Validate migration paths
- Gather early feedback

### Phase 3: Beta Release (v6.0.0-beta.1)
- Announce beta to users
- Request migration testing
- Fix issues discovered during beta
- Finalize documentation

### Phase 4: Release Candidate (v6.0.0-rc.1)
- Final validation
- No new features
- Only critical bug fixes

### Phase 5: GA Release (v6.0.0)
- Full release
- Announce with migration guide
- Monitor for issues
- Provide support for migrations

**Estimated Timeline:**
- v5.11.0 release: 2025-11-29
- User migration period: 2025-12 through 2026-04 (6 months)
- v6.0.0-alpha.1: 2026-03
- v6.0.0-beta.1: 2026-04
- v6.0.0-rc.1: 2026-05
- v6.0.0 GA: 2026-06 (Q2 2026)

---

## Success Criteria

v6.0.0 is ready for release when:

- ✅ All deprecated variables removed
- ✅ Type safety improved (`any` type eliminated)
- ✅ All tests passing with new variable names
- ✅ Migration tested on at least 3 real production deployments
- ✅ UPGRADE-6.0.md is comprehensive and tested
- ✅ No new features added (pure cleanup/improvement)
- ✅ All InfraHouse internal modules upgraded successfully
- ✅ Documentation is complete and accurate
- ✅ Migration tooling (if provided) is tested

---

## Communication Plan

### v5.11.0 Release (Now)
- ✅ Add deprecation warnings
- ✅ Create UPGRADE-6.0.md (draft)
- ✅ Document in CHANGELOG.md
- ✅ Add warnings to README.md

### 3 Months Before v6.0.0 (2026-03)
- Email announcement of v6.0.0 plans
- Blog post explaining breaking changes and rationale
- Provide timeline for v6.0.0 release
- Encourage users to test migrations

### 1 Month Before v6.0.0 (2026-05)
- Final reminder email
- Release v6.0.0-rc.1 for final testing
- Offer office hours / support for migrations
- Update Terraform registry documentation

### v6.0.0 Release (2026-06)
- Major announcement
- Link to comprehensive UPGRADE-6.0.md
- Celebrate improved code quality!
- Monitor GitHub issues closely for first 2 weeks

---

## Rollback Plan

If v6.0.0 causes major issues:

1. **Immediate:** Remove from Terraform registry "latest" tag
2. **Communication:** Announce issue and recommend staying on v5.x
3. **Fix:** Address critical issues in v6.0.1
4. **Testing:** Thorough validation before re-releasing
5. **Lesson Learned:** Document what went wrong and how to prevent

---

## Questions to Answer Before v6.0.0

- [ ] Does s3-bucket module support all required features?
- [ ] Should we migrate to s3-bucket module or defer to v7.0.0?
- [ ] Are there other breaking changes we want to include?
- [ ] Should we consolidate Vanta variables?
- [ ] What's the minimum migration testing we require?
- [ ] Do we need automated migration tooling?
- [ ] What's our support plan for users during migration?
- [ ] Should we offer paid migration support for enterprise users?

---

## Notes

- Keep this document updated as decisions are made
- Review quarterly during v5.x maintenance
- Use GitHub issues to track v6.0.0 specific work
- Consider creating a v6.0.0 milestone in GitHub
- Remember: Breaking changes should IMPROVE the module, not just change it

---

**Document Maintained By:** InfraHouse Team
**Last Updated:** 2025-11-29
**Next Review:** 2026-02 (3 months from v5.11.0 release)